{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4cdf5",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from pykubegrader.tokens.validate_token import validate_token\n",
    "\n",
    "validate_token(\"type the key provided by your instructor here\", assignment=\"week9-quiz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "validate_token(assignment=\"week9-quiz\")\n",
    "\n",
    "# You must make sure to run all cells in sequence using shift + enter or you might encounter errors\n",
    "from pykubegrader.initialize import initialize_assignment\n",
    "\n",
    "responses = initialize_assignment(\n",
    "    \"ML_quiz_q\", \"week_9\", \"quiz\", assignment_points=10.0, assignment_tag=\"week9-quiz\"\n",
    ")\n",
    "\n",
    "# Initialize Otter\n",
    "import otter\n",
    "\n",
    "grader = otter.Notebook(\"ML_quiz_q.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# ❓✍️ Training MNIST Handwritten Digits 🖋️\n",
    "\n",
    "The MNIST dataset is a classic benchmark in machine learning, consisting of grayscale images of handwritten digits (0-9). This problem focuses on building a **classification model** using a **Support Vector Machine (SVM)** to recognize handwritten digits from the dataset. 🤖\n",
    "\n",
    "## Key Steps in the Problem: 🗝️\n",
    "\n",
    "1. **Load the MNIST Dataset** 📥  \n",
    "   - The dataset is retrieved from OpenML and consists of **784 features (28×28 pixel images)** and **70,000 samples**. 📊\n",
    "   - The labels represent digit classes from **0 to 9**. 🔢\n",
    "\n",
    "2. **Data Preprocessing** 🔄  \n",
    "   - Pixel values are normalized to **[0,1]** for better numerical stability. 📏\n",
    "   - The dataset is split into a **training set (80%)** and a **test set (20%)**. 📚\n",
    "\n",
    "3. **Model Selection: Support Vector Machine (SVM)** 🤔  \n",
    "   - An **SVM classifier with stochastic gradient descent (SGDClassifier)** is used. 🏃‍♂️  \n",
    "   - The loss function is set to `\"log_loss\"`, which enables logistic regression-like behavior. ⚙️\n",
    "\n",
    "4. **Training the Model** 🏋️‍♂️  \n",
    "   - The SVM model is trained using the processed dataset. 📈\n",
    "\n",
    "5. **Model Evaluation** 📊  \n",
    "   - Predictions are made on the test set. 🔍\n",
    "   - Accuracy, classification report, and a confusion matrix are used to assess performance. 📑\n",
    "\n",
    "6. **Visualization** 🖼️  \n",
    "   - A confusion matrix is plotted to analyze model errors in classifying digits. 📉\n",
    "\n",
    "This question tests the understanding of **machine learning pipelines**, **data preprocessing**, and **model evaluation** while applying SVM for handwritten digit recognition. Students should focus on **understanding how data is transformed and how performance metrics are interpreted**. 🎓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "otter_answer_cell",
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# import necessary libraries\n",
    "# from sklearn import datasets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "...\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Step 1: Load the MNIST dataset\n",
    "# load the MNIST dataset, to the variable mnist using the datasets.fetch_openml function\n",
    "# get version 1 of the MNIST dataset, by setting the option argument version=1\n",
    "# set the as_frame argument to False, by setting the option as_frame=False\n",
    "...\n",
    "\n",
    "# Unpack the data by assigning the mnist.data to X and the mnist.target to y\n",
    "# You want to ensure that the datatype is in np.uint8, do this by using the astype method of the object mnist.target, and setting the option to dtype=np.uint8\n",
    "...\n",
    "\n",
    "# Step 2: Preprocess the data\n",
    "# Normalize pixel values to range [0,1], by dividing the X object by 255.0\n",
    "...\n",
    "\n",
    "# Split the data into training and testing sets, by using the train_test_split function, and setting the test_size to 0.2, and random_state to 42\n",
    "...\n",
    "\n",
    "# Step 3: Select a model (Support Vector Machine)\n",
    "# Instantiate the SGDClassifier model, by setting the loss to 'log_loss', max_iter to 2000, tol to 1e-5, and random_state to 42\n",
    "...\n",
    "\n",
    "# Step 4: Train the model\n",
    "# Fit the model to the training data, by using the fit method of the model object, and passing in the X_train and y_train data\n",
    "...\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "# Predict the test data, by using the predict method of the model object, and passing in the X_test data\n",
    "...\n",
    "\n",
    "# Calculate the accuracy of the model, by using the accuracy_score function, and passing in the y_test and y_pred data\n",
    "...\n",
    "\n",
    "# Step 6: Display results\n",
    "# this is optional, you can print the accuracy of the model, and the classification report\n",
    "# Print the accuracy of the model\n",
    "print(f\"Model Accuracy: {accuracy:.4f}\")\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# create a plot of the confusion matrix\n",
    "# create a figure and axis object, using the subplots function\n",
    "# set the figsize to (8, 6), this is an optional parameter figsize\n",
    "...\n",
    "\n",
    "# plot the confusion matrix\n",
    "# call the confusion_matrix function, and pass in the y_test and y_pred data\n",
    "# on the ax object, call the imshow method, and pass in the confusion matrix, and set the cmap to 'Blues', and the interpolation to 'nearest'\n",
    "...\n",
    "\n",
    "# set the title of the plot to \"Confusion Matrix\" using the plt object\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"MNIST-Handwritten-Digits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3edb82",
   "metadata": {},
   "source": [
    "## Submitting Assignment\n",
    "\n",
    "Please run the following block of code using `shift + enter` to submit your assignment, you should see your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f80750",
   "metadata": {
    "deletable": false,
    "editable": true,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from pykubegrader.tokens.validate_token import validate_token\n",
    "\n",
    "validate_token(assignment=\"week9-quiz\")\n",
    "\n",
    "\n",
    "from pykubegrader.submit.submit_assignment import submit_assignment\n",
    "\n",
    "submit_assignment(\"week9-quiz\", \"ML_quiz_q\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "MNIST-Handwritten-Digits": {
     "name": "MNIST-Handwritten-Digits",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token(assignment='week9-quiz')\n>>> import sys\n>>> max_question_points = str(10.0)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(10.0)\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token(assignment='week9-quiz')\n>>> log_variable('total-points', f'week9-quiz, ML_quiz_q', 10.0)\n>>> question_id = 'MNIST-Handwritten-Digits-1'\n>>> max_score = 1.0\n>>> score = 0\n>>> assert 'sklearn' in sys.modules, 'scikit-learn is not imported.'\n>>> assert 'numpy' in sys.modules, 'numpy is not imported.'\n>>> assert 'matplotlib.pyplot' in sys.modules, 'matplotlib.pyplot is not imported.'\n>>> if 'sklearn' in sys.modules and 'numpy' in sys.modules and ('matplotlib.pyplot' in sys.modules):\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('ML_quiz_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Failed: Required libraries are not imported correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: Required libraries are imported correctly!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token(assignment='week9-quiz')\n>>> question_id = 'MNIST-Handwritten-Digits-2'\n>>> max_score = 1.0\n>>> score = 0\n>>> condition1 = 'mnist' in globals()\n>>> assert condition1, 'mnist dataset is not defined.'\n>>> condition2 = hasattr(mnist, 'data') and hasattr(mnist, 'target')\n>>> assert condition2, 'MNIST dataset is missing expected attributes.'\n>>> if condition1 and condition2:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('ML_quiz_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Failed: MNIST dataset is not loaded correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: MNIST dataset is loaded correctly!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token(assignment='week9-quiz')\n>>> question_id = 'MNIST-Handwritten-Digits-3'\n>>> max_score = 1.0\n>>> score = 0\n>>> condition1 = 'X' in globals() and 'y' in globals()\n>>> assert condition1, 'X or y is not defined.'\n>>> condition2 = isinstance(X, np.ndarray)\n>>> assert condition2, 'X is not a numpy array.'\n>>> condition3 = isinstance(y, np.ndarray)\n>>> assert condition3, 'y is not a numpy array.'\n>>> condition4 = y.dtype == np.uint8\n>>> assert condition4, 'y is not of type np.uint8.'\n>>> if condition1 and condition2 and condition3 and condition4:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('ML_quiz_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Failed: Data is not correctly unpacked or incorrect types.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: Data is unpacked and types are correct!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token(assignment='week9-quiz')\n>>> question_id = 'MNIST-Handwritten-Digits-4'\n>>> max_score = 1.0\n>>> score = 0\n>>> condition = np.max(X) <= 1.0 and np.min(X) >= 0.0\n>>> assert condition, 'X is not properly normalized.'\n>>> if condition:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('ML_quiz_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> responses = update_responses(question_id, str(X))\n",
         "failure_message": "Failed: Data is not normalized correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: Data is normalized correctly!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token(assignment='week9-quiz')\n>>> question_id = 'MNIST-Handwritten-Digits-5'\n>>> max_score = 1.0\n>>> score = 0\n>>> condition1 = 'X_train' in globals() and 'X_test' in globals()\n>>> assert condition1, 'X_train or X_test is not defined.'\n>>> condition2 = 'y_train' in globals() and 'y_test' in globals()\n>>> assert condition2, 'y_train or y_test is not defined.'\n>>> condition3 = len(X_train) > len(X_test)\n>>> assert condition3, 'Training set is smaller than test set.'\n>>> condition4 = len(y_train) > len(y_test)\n>>> assert condition4, 'Training labels are smaller than test labels.'\n>>> if condition1 and condition2 and condition3 and condition4:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('ML_quiz_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Failed: Data is not split correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: Data is split into training and test sets correctly!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token(assignment='week9-quiz')\n>>> question_id = 'MNIST-Handwritten-Digits-6'\n>>> max_score = 1.0\n>>> score = 0\n>>> condition1 = 'model' in globals()\n>>> assert condition1, 'model is not defined.'\n>>> condition2 = isinstance(model, SGDClassifier)\n>>> assert condition2, 'model is not an instance of SGDClassifier.'\n>>> if condition1 and condition2:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('ML_quiz_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Failed: Model is not instantiated correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: Model is instantiated correctly!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token(assignment='week9-quiz')\n>>> question_id = 'MNIST-Handwritten-Digits-7'\n>>> max_score = 1.0\n>>> score = 0\n>>> condition = 'y_pred' in globals()\n>>> assert condition, 'y_pred is not defined.'\n>>> condition1 = isinstance(y_pred, np.ndarray)\n>>> assert condition1, 'y_pred is not a numpy array.'\n>>> condition2 = len(y_pred) == len(y_test)\n>>> assert condition2, 'Predictions do not match test set size.'\n>>> if condition and condition1 and condition2:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('ML_quiz_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Failed: Predictions are not made correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: Predictions are made correctly!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token(assignment='week9-quiz')\n>>> question_id = 'MNIST-Handwritten-Digits-8'\n>>> max_score = 1.0\n>>> score = 0\n>>> condition = 'accuracy' in globals()\n>>> assert condition, 'accuracy is not defined.'\n>>> condition1 = isinstance(accuracy, float)\n>>> assert condition1, 'accuracy is not a float.'\n>>> condition2 = 0.9 <= accuracy <= 1.0\n>>> assert condition2, 'accuracy is out of bounds.'\n>>> if condition and condition1 and condition2:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('ML_quiz_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Failed: Model accuracy is not computed correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: Model accuracy is computed correctly!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token(assignment='week9-quiz')\n>>> import numpy as np\n>>> question_id = 'MNIST-Handwritten-Digits-9'\n>>> max_score = 1.0\n>>> score = 0\n>>> out = np.sum(ax.images[0].get_array().flatten(), axis=0)\n>>> assert out == 14000\n>>> if out == 14000:\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('ML_quiz_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Failed: Confusion matrix is not displayed correctly.",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: Confusion matrix is displayed correctly!"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> import base64\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token(assignment='week9-quiz')\n>>> question_id = 'MNIST-Handwritten-Digits-10'\n>>> max_score = 1.0\n>>> score = 0\n>>> exec(base64.b64decode('b3V0MiA9IG5wLmFycmF5KFtbMTMwOSwgICAgMiwgICAgNCwgICAgMCwgICAgMSwgICAgMywgICAxNCwgICAgMiwgICAgOCwgICAgMF0sClsgICAwLCAxNTU1LCAgICA0LCAgICA4LCAgICAxLCAgICA5LCAgICAyLCAgICA0LCAgIDE2LCAgICAxXSwKWyAgIDgsICAgMjQsIDEyMjQsICAgMjEsICAgMjAsICAgMTAsICAgMjIsICAgMTQsICAgMzMsICAgIDRdLApbICAgOSwgICAxMCwgICAzMSwgMTI4NiwgICAgMSwgICAzNywgICAgOSwgICAxMSwgICAyMiwgICAxN10sClsgICA1LCAgICAzLCAgICA5LCAgICA3LCAxMjAxLCAgICAyLCAgIDEyLCAgICA2LCAgIDEzLCAgIDM3XSwKWyAgIDgsICAgMTQsICAgIDUsICAgNjgsICAgMTUsIDEwODksICAgMjQsICAgIDMsICAgMzgsICAgIDldLApbICAgNSwgICAgNSwgICAxMiwgICAgMSwgICAxMSwgICAyMSwgMTMzNiwgICAgMCwgICAgNSwgICAgMF0sClsgIDEwLCAgICA5LCAgIDI2LCAgICA1LCAgIDEyLCAgICA3LCAgICAwLCAxMzk2LCAgICA1LCAgIDMzXSwKWyAgMTMsICAgMzQsICAgMTYsICAgNDcsICAgIDgsICAgMzIsICAgMTMsICAgIDUsIDExNzEsICAgMThdLApbICAgOSwgICAxMSwgICAgNiwgICAyNiwgICA1NywgICAxMSwgICAgMCwgICA0NywgICAxOCwgMTIzNV1dKQ==').decode())\n>>> assert all(out2.flatten() == ax.images[0].get_array().flatten().data)\n>>> if all(out2.flatten() == ax.images[0].get_array().flatten().data):\n...     score = 1.0\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('ML_quiz_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Failed: Confusion matrix is not computed correctly. Check that you fixed your seeds",
         "hidden": false,
         "locked": false,
         "points": 1,
         "success_message": "Success: Confusion matrix is computed correctly!"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}