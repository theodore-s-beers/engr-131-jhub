{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from pykubegrader.tokens.validate_token import validate_token\n",
    "\n",
    "validate_token(\"type the key provided by your instructor here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# You must make sure to run all cells in sequence using shift + enter or you might encounter errors\n",
    "from pykubegrader.initialize import initialize_assignment\n",
    "\n",
    "responses = initialize_assignment(\n",
    "    \"1_quiz_2_q\", \"week_2\", \"quiz\", assignment_points=14.5, assignment_tag=\"week2-quiz\"\n",
    ")\n",
    "\n",
    "# Initialize Otter\n",
    "import otter\n",
    "\n",
    "grader = otter.Notebook(\"1_quiz_2_q.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# â“ Python Basics: Data Structures and Types Quiz ðŸ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Run this block of code by pressing Shift + Enter to display the question\n",
    "from questions._1_quiz_2_q import Question1\n",
    "\n",
    "Question1().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Run this block of code by pressing Shift + Enter to display the question\n",
    "from questions._1_quiz_2_q import Question2\n",
    "\n",
    "Question2().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Run this block of code by pressing Shift + Enter to display the question\n",
    "from questions._1_quiz_2_q import Question3\n",
    "\n",
    "Question3().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Engine Performance Analysis ðŸ”§\n",
    "\n",
    "### Instructions:\n",
    "\n",
    "Create a Python dictionary to analyze engine test data. Your solution must include:\n",
    "\n",
    "1. Create a dictionary named `engine_data` with these EXACT keys and values:\n",
    "   - `model`: String \"V6-3000\"\n",
    "   - `displacement`: Float 3.0\n",
    "   - `test_temperatures`: List [85, 90, 88, 92, 87]  # in Celsius\n",
    "   - `performance_metrics`: Dictionary containing:\n",
    "     - `horsepower`: Float 280.5\n",
    "     - `torque`: Float 350.8  # Nm\n",
    "\n",
    "2. Calculate these values (store each in its own variable):\n",
    "   - `avg_temp`: Average of test_temperatures (use `sum` and `len`)\n",
    "   - `max_temp`: Maximum temperature from test_temperatures (use `max`)\n",
    "   - `power_density`: Horsepower divided by displacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "# Create the engine data dictionary with exact values\n",
    "...\n",
    "\n",
    "\n",
    "# Calculate required values\n",
    "...\n",
    "\n",
    "# We have provided the code to print the results for you\n",
    "# Print results for verification (optional but helpful)\n",
    "print(f\"Average Temperature: {avg_temp:.1f}Â°C\")\n",
    "print(f\"Maximum Temperature: {max_temp}Â°C\")\n",
    "print(f\"Power Density: {power_density:.1f} hp/L\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "grader.check(\"question-Engine-Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Submitting Assignment\n",
    "\n",
    "Please run the following block of code using `shift + enter` to submit your assignment, you should see your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "skip-execution"
    ]
   },
   "outputs": [],
   "source": [
    "from pykubegrader.tokens.validate_token import validate_token\n",
    "\n",
    "validate_token()\n",
    "\n",
    "\n",
    "from pykubegrader.submit.submit_assignment import submit_assignment\n",
    "\n",
    "submit_assignment(\"week2-quiz\", \"1_quiz_2_q\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "engr131_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "question-Engine-Data": {
     "name": "question-Engine-Data",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> max_question_points = str(6.5)\n>>> earned_points = 0\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n>>> os.environ['TOTAL_POINTS_FREE_RESPONSE'] = str(6.5)\n>>> from pykubegrader.tokens.validate_token import validate_token\n>>> validate_token()\n>>> log_variable('total-points', f'Reading-Week-X, 1_quiz_2_q', 6.5)\n>>> question_id = 'question-Engine-Data-1'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, isinstance(engine_data, dict))\n>>> assert isinstance(engine_data, dict), 'engine_data must be a dictionary'\n>>> if isinstance(engine_data, dict):\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "Not a dictionary - make sure you create engine_data as a dictionary",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Dictionary type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-2'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, str(type(engine_data['model'])))\n>>> assert isinstance(engine_data['model'], str), 'model must be a string'\n>>> if isinstance(engine_data['model'], str):\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The 'model' value must be a string (str)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Model data type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-3'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, str(type(engine_data['displacement'])))\n>>> assert isinstance(engine_data['displacement'], float), 'displacement must be a float'\n>>> if isinstance(engine_data['displacement'], float):\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The 'displacement' value must be a float (not an int)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Displacement data type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-4'\n>>> max_score = 0.5\n>>> score = 0\n>>> assert isinstance(engine_data['test_temperatures'], list), 'test_temperatures must be a list'\n>>> if isinstance(engine_data['test_temperatures'], list):\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The 'test_temperatures' value must be a list",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Test temperatures data type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-5'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, str(type(engine_data['performance_metrics'])))\n>>> assert isinstance(engine_data['performance_metrics'], dict), 'performance_metrics must be a dictionary'\n>>> if isinstance(engine_data['performance_metrics'], dict):\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The 'performance_metrics' value must be a dictionary",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Performance metrics data type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-6'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, engine_data['model'])\n>>> assert engine_data['model'] == 'V6-3000', \"model must be exactly 'V6-3000'\"\n>>> if engine_data['model'] == 'V6-3000':\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The model must be exactly 'V6-3000' (check spelling and capitalization)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Model value is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-7'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, abs(engine_data['displacement'] - 3.0))\n>>> assert abs(engine_data['displacement'] - 3.0) < 0.001, 'displacement must be exactly 3.0'\n>>> if abs(engine_data['displacement'] - 3.0) < 0.001:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The displacement must be exactly 3.0 (as a float)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Displacement value is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-8'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, engine_data['test_temperatures'])\n>>> conditional = engine_data['test_temperatures'] == [85, 90, 88, 92, 87]\n>>> assert conditional, 'test_temperatures must match exactly'\n>>> if conditional:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The test_temperatures list must be exactly [85, 90, 88, 92, 87]",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Test temperatures list is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-9'\n>>> max_score = 0.5\n>>> score = 0\n>>> assert abs(engine_data['performance_metrics']['horsepower'] - 280.5) < 0.001, 'horsepower must be exactly 280.5'\n>>> if abs(engine_data['performance_metrics']['horsepower'] - 280.5) < 0.001:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The horsepower must be exactly 280.5 (as a float)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Horsepower value is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-10'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, abs(engine_data['performance_metrics']['torque']))\n>>> assert abs(engine_data['performance_metrics']['torque'] - 350.8) < 0.001, 'torque must be exactly 350.8'\n>>> if abs(engine_data['performance_metrics']['torque'] - 350.8) < 0.001:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "The torque must be exactly 350.8 (as a float)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Torque value is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-11'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, avg_temp)\n>>> assert isinstance(avg_temp, float), 'avg_temp must be a float'\n>>> assert abs(avg_temp - 88.4) < 0.001, 'avg_temp calculation incorrect - should be 88.4'\n>>> if isinstance(avg_temp, float) and abs(avg_temp - 88.4) < 0.001:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "avg_temp must be a float type (use division with sum and len)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Average temperature data type is correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-12'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, max_temp)\n>>> assert isinstance(max_temp, int), 'max_temp must be an integer'\n>>> assert max_temp == 92, 'max_temp calculation incorrect - should be 92'\n>>> if isinstance(max_temp, int) and max_temp == 92:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "max_temp must be an integer with value 92 (use max() function)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Maximum temperature data type and value are correct"
        },
        {
         "code": ">>> from pykubegrader.telemetry import ensure_responses, log_variable, score_question, submit_question, telemetry, update_responses\n>>> import os\n>>> question_id = 'question-Engine-Data-13'\n>>> max_score = 0.5\n>>> score = 0\n>>> responses = update_responses(question_id, power_density)\n>>> assert isinstance(power_density, float), 'power_density must be a float'\n>>> assert abs(power_density - 93.5) < 0.1, 'power_density calculation incorrect - should be 93.5'\n>>> if isinstance(power_density, float) and abs(power_density - 93.5) < 0.1:\n...     score = 0.5\n>>> earned_points = float(os.environ.get('EARNED_POINTS', 0))\n>>> earned_points += score\n>>> log_variable('1_quiz_2_q', f'{score}, {max_score}', question_id)\n>>> os.environ['EARNED_POINTS'] = str(earned_points)\n",
         "failure_message": "power_density must be a float equal to 93.5 (horsepower/displacement)",
         "hidden": false,
         "locked": false,
         "points": 0.5,
         "success_message": "Power density calculation is correct"
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
